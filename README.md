# Introduction

Channel Attention was first used as a squeeze and excitation block for classification, which generates channel attention maps by using the relationship between the channels.
![SE](SE.jpg?raw=true "SE")


# Channel-Attention-family

## 2017 
  * Squeeze-and-Excitation Networks(CVPR) [[paper]](https://arxiv.org/abs/1709.01507)[[code]](https://github.com/hujie-frank/SENet)
## 2018 
  * Image Super-Resolution Using Very Deep Residual Channel Attention Networks(ECCV).[[paper]](https://arxiv.org/abs/1807.02758)[[code]](https://github.com/yulunzhang/RCAN)
  * CBAM: Convolutional Block Attention Module(ECCV).[[paper]](https://arxiv.org/abs/1807.06521)[[keras]](https://github.com/kobiso/CBAM-keras)[[code]](https://github.com/luuuyi/CBAM.PyTorch)
  * BAM: Bottleneck Attention Module(BMVC).[[paper]](https://arxiv.org/abs/1807.06514)[[code]](https://github.com/Jongchan/attention-module)
  * Learning a Discriminative Feature Network for Semantic Segmentation(CVPR).[[paper]](https://arxiv.org/abs/1804.09337)[[code]](https://github.com/ycszen/TorchSeg)
## 2019
  * RCA-U-Net: Residual Channel Attention U-Net for Fast Tissue Quantification in Magnetic Resonance Fingerprinting(MICCAI).[[paper]](https://link.springer.com/chapter/10.1007/978-3-030-32248-9_12)
  * Bilinear Attention Networks for Person Retrieval(ICCV).[[paper]](https://openaccess.thecvf.com/content_ICCV_2019/html/Fang_Bilinear_Attention_Networks_for_Person_Retrieval_ICCV_2019_paper.html)[[code]](https://github.com/jnhwkim/ban-vqa)
   * DenseNet with Deep Residual Channel-Attention Blocks for Single Image Super
Resolution(CVPR Workshop).[[paper]](https://openaccess.thecvf.com/content_CVPRW_2019/html/NTIRE/Jang_DenseNet_With_Deep_Residual_Channel-Attention_Blocks_for_Single_Image_Super_CVPRW_2019_paper.html)[[code]](https://github.com/dong-won-jang/DRCA)
## 2020
  * ECA-Net: Efficient Channel Attention for Deep Convolutional Neural Networks(CVPR).[[paper]](https://arxiv.org/abs/1910.03151)[[code]](https://github.com/BangguWu/ECANet) 
  * ResNeSt: Split-Attention Networks.[[paper]](https://arxiv.org/abs/2004.08955)[[code]](https://github.com/zhanghang1989/ResNeSt)
  * Channel Attention Residual U-Net for Retinal Vessel Segmentation.[[paper]](https://arxiv.org/abs/2004.03702)[[code]](https://github.com/clguo/CAR-UNet)

